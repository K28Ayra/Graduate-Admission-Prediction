{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2b2d22-667a-4226-b90b-dc0d37f77efc",
   "metadata": {},
   "source": [
    "# regression model based problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02a8564-bc2c-4f89-8986-57bfe11a6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb775b0-954f-4636-b20e-6e77cb2979c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ceafaac-badd-4eec-96d0-9659f0fcba7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ad06db-8f16-4123-92ea-e32de075112b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d6fc2b2-f0f1-4e39-a356-9d81e609367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13440a15-4073-4707-be07-90a0d632bab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  500.000000  500.000000   500.000000         500.000000  500.000000   \n",
       "mean   250.500000  316.472000   107.192000           3.114000    3.374000   \n",
       "std    144.481833   11.295148     6.081868           1.143512    0.991004   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    125.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    250.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    375.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "            LOR         CGPA    Research  Chance of Admit   \n",
       "count  500.00000  500.000000  500.000000         500.00000  \n",
       "mean     3.48400    8.576440    0.560000           0.72174  \n",
       "std      0.92545    0.604813    0.496884           0.14114  \n",
       "min      1.00000    6.800000    0.000000           0.34000  \n",
       "25%      3.00000    8.127500    0.000000           0.63000  \n",
       "50%      3.50000    8.560000    1.000000           0.72000  \n",
       "75%      4.00000    9.040000    1.000000           0.82000  \n",
       "max      5.00000    9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53918afb-150b-4ef1-9988-25fc59da5b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fbe8d40-d09f-489f-beee-f48b0ce1e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns= ['Serial No.'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1396948f-d032-4157-803e-1fe29377afe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0          337          118                  4  4.5   4.5  9.65         1   \n",
       "1          324          107                  4  4.0   4.5  8.87         1   \n",
       "2          316          104                  3  3.0   3.5  8.00         1   \n",
       "3          322          110                  3  3.5   2.5  8.67         1   \n",
       "4          314          103                  2  2.0   3.0  8.21         0   \n",
       "..         ...          ...                ...  ...   ...   ...       ...   \n",
       "495        332          108                  5  4.5   4.0  9.02         1   \n",
       "496        337          117                  5  5.0   5.0  9.87         1   \n",
       "497        330          120                  5  4.5   5.0  9.56         1   \n",
       "498        312          103                  4  4.0   5.0  8.43         0   \n",
       "499        327          113                  4  4.5   4.5  9.04         0   \n",
       "\n",
       "     Chance of Admit   \n",
       "0                0.92  \n",
       "1                0.76  \n",
       "2                0.72  \n",
       "3                0.80  \n",
       "4                0.65  \n",
       "..                ...  \n",
       "495              0.87  \n",
       "496              0.96  \n",
       "497              0.93  \n",
       "498              0.73  \n",
       "499              0.84  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c71556ff-08ee-45e5-abd8-9ab682edb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract x and y\n",
    "\n",
    "x= df.iloc[:, 0:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e474e5db-8a0d-4dab-83ab-055d61e3a4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0aa217df-790f-4a1c-8c50-778bb98f4b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43b69451-ff73-4b4f-8959-79a7d543be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "##we gotta scale the dta by minmax\n",
    "#bcz in sop, lor.. values are so close n they create prblm \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f87d2a0b-0193-44f5-9205-e16fc684dca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f97abd35-1d6f-479a-9b3d-e38063c8f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCLAING\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ea09a2a-f4a6-4a0d-b16e-740cb0d69197",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63aaeb4a-f93c-4568-9f3d-89a6017c0d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab1dffce-dd72-41d4-8fce-4264597a9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19c18913-fc00-4606-8c55-b4811e98580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the neural n/w\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9800de0-9aa8-4c15-a8f6-78b47ccba739",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(7, activation = 'relu', input_dim=7))\n",
    "model.add(Dense(7, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc59f961-ffb5-4f08-be93-9acf1d7cc891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120 (480.00 Byte)\n",
      "Trainable params: 120 (480.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c16c7bb9-58e0-4480-b2d0-63507824a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= 'mean_squared_error', optimizer= 'Adam', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49a1f093-3dc0-4116-93e5-9276014c79fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 43ms/step - loss: 0.7856 - accuracy: 0.0000e+00 - val_loss: 0.7274 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5736 - accuracy: 0.0000e+00 - val_loss: 0.5299 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4218 - accuracy: 0.0000e+00 - val_loss: 0.4006 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3236 - accuracy: 0.0000e+00 - val_loss: 0.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2570 - accuracy: 0.0000e+00 - val_loss: 0.2509 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.2039 - accuracy: 0.0000e+00 - val_loss: 0.1983 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.0000e+00 - val_loss: 0.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.1223 - accuracy: 0.0000e+00 - val_loss: 0.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0905 - accuracy: 0.0000e+00 - val_loss: 0.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0637 - accuracy: 0.0000e+00 - val_loss: 0.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0431 - accuracy: 0.0000e+00 - val_loss: 0.0364 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0279 - accuracy: 0.0000e+00 - val_loss: 0.0235 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0187 - accuracy: 0.0000e+00 - val_loss: 0.0158 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0134 - accuracy: 0.0000e+00 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0109 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0099 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0096 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0093 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0092 - accuracy: 0.0000e+00 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0066 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0058 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 100, validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbc4ea0c-dcec-4eb6-a36a-9f8cf64eb02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "645b9329-88a8-4a6d-a3ad-3b716c2e8402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7943471650134443"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score( y_test, y_pred)\n",
    "\n",
    "##Rsquared repreents the proportion of target varivale obtained from independant variable \n",
    "##value lies betweeen 0 and 1\n",
    "# 0= no variability\n",
    "#1= very good variability in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c5e409c-842b-45c9-bba3-c9f84e031969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18cf9393b10>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a67adbd8-0ef9-4daa-a527-e3b0436a6f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18cfa5a2cd0>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189f735-d95a-4206-aafa-22bb41bde93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916edb08-df6b-445a-9d08-772ce8ac2e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616245a-8556-447d-a5a5-bf558a9212bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
